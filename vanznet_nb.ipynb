{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'vanznames.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, 'r') as f:\n",
    "    names_raw = list(map(lambda x: x.replace('\\n', ''), f.readlines()))\n",
    "    \n",
    "all_letters = list(set(\"\".join(names_raw)))\n",
    "n_letters = len(all_letters) + 1 # including EOS\n",
    "\n",
    "def encode_name(name):\n",
    "    return [all_letters.index(s) for s in name]\n",
    "\n",
    "names_enc = [encode_name(name) for name in names_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "[147, 27, 63, 25, 78, 110, 157, 65, 3, 13, 65, 23, 65, 8, 23, 147, 65, 110, 125, 142]\n"
     ]
    }
   ],
   "source": [
    "print(n_letters)\n",
    "print(names_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class VanzNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dor=0.15):\n",
    "        super(VanzNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        total_input_size = input_size + hidden_size\n",
    "        self.i2h = nn.Linear(total_input_size, hidden_size)\n",
    "        self.i2o = nn.Linear(total_input_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(dor)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot matrix for characters\n",
    "def name2input(name_enc):\n",
    "    \"\"\"    \n",
    "    dim: [len_name * 1 * n_letters]\n",
    "    e.g. KASPAROV -> [OneHot(K), OneHot(A), ..., OneHot(V)]\n",
    "    \"\"\"\n",
    "    tensor = torch.zeros(len(name_enc), 1, n_letters)\n",
    "    for i, n in enumerate(name_enc):\n",
    "        tensor[i][0][n] = 1\n",
    "    return tensor\n",
    "\n",
    "def name2target(name_enc):\n",
    "    \"\"\"\n",
    "    dim: [len_name]\n",
    "    e.g. target(KASPAROV) -> ASPAROV<EOS> -> [Idx(A), Idx(S), ..., Idx(EOS)]\n",
    "    \"\"\"\n",
    "    return torch.LongTensor(name_enc[1:] + [n_letters - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "rnn = VanzNet(n_letters, hidden_size, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/1000: Loss 19.474829\n",
      "50/1000: Loss 23.199406\n",
      "75/1000: Loss 22.645500\n",
      "100/1000: Loss 22.328510\n",
      "125/1000: Loss 24.708447\n",
      "150/1000: Loss 20.443289\n",
      "175/1000: Loss 22.385340\n",
      "200/1000: Loss 26.498999\n",
      "225/1000: Loss 30.261909\n",
      "250/1000: Loss 26.457685\n",
      "275/1000: Loss 27.005342\n",
      "300/1000: Loss 25.344959\n",
      "325/1000: Loss 21.718395\n",
      "350/1000: Loss 22.119383\n",
      "375/1000: Loss 23.609180\n",
      "400/1000: Loss 25.369316\n",
      "425/1000: Loss 22.199478\n",
      "450/1000: Loss 21.851562\n",
      "475/1000: Loss 23.096273\n",
      "500/1000: Loss 22.436003\n",
      "525/1000: Loss 25.919310\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "epochs = 1000\n",
    "print_every = 25\n",
    "max_training_size = -1\n",
    "\n",
    "if max_training_size > 0:\n",
    "    names_train = names_enc[:max_training_size]\n",
    "else:\n",
    "    names_train = names_enc\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    for name in names_train:\n",
    "        input_tensor = name2input(name)\n",
    "        target_tensor = name2target(name)\n",
    "        target_tensor.unsqueeze_(-1)\n",
    "        # print(input_tensor)\n",
    "        # print(target_tensor)\n",
    "        hidden = rnn.initHidden()\n",
    "        optim.zero_grad()\n",
    "        loss = 0\n",
    "        for i in range(input_tensor.size(0)):\n",
    "            output, hidden = rnn(input_tensor[i], hidden)\n",
    "            loss += criterion(output, target_tensor[i])\n",
    "            loss_epoch += loss\n",
    "        loss /= input_tensor.size(0)\n",
    "        loss_epoch /= input_tensor.size(0)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    losses.append(loss_epoch / len(names_train))\n",
    "    \n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        print(\"%d/%d: Loss %f\" % (epoch+1, epochs, loss_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_char(output):\n",
    "    topv, topi = output.topk(1)\n",
    "    idx = topi[0][0]\n",
    "    if idx == n_letters - 1:\n",
    "        return 'EOS'\n",
    "    else:\n",
    "        return all_letters[idx]\n",
    "\n",
    "def sample_name(start_char):\n",
    "    name_sample = start_char\n",
    "    if not (start_char in all_letters):\n",
    "        return \"Invalid start character!\"\n",
    "    else:\n",
    "        start_char_enc = [all_letters.index(start_char)]\n",
    "        input_tensor = name2input(start_char_enc)        \n",
    "        hidden = rnn.initHidden()\n",
    "        out_char = \"\"\n",
    "        \n",
    "        while True:\n",
    "            output, hidden = rnn(input_tensor[0], hidden)\n",
    "            out_char = reconstruct_char(output)\n",
    "            if out_char == 'EOS':\n",
    "                break\n",
    "            name_sample += out_char\n",
    "            input_tensor = name2input([all_letters.index(out_char)])\n",
    "    \n",
    "    return name_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "การัก เอ็มใจร้าย\n",
      "คำเพิ เอ็ม\n",
      "มี่ เฉยย\n",
      "จัน รัง สายสุข\n",
      "วัน พลู\n",
      "รัก' เอ็น\n",
      "บอร เทียย\n"
     ]
    }
   ],
   "source": [
    "start_letters = ['ก', 'ค', 'ม', 'จ', 'ว', 'ร', 'บ']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sp in start_letters:\n",
    "        print(sample_name(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
